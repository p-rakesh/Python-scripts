{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHGeWvUWYxWHMRGmgMLtjq"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "japWX0w06exO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from keras import models, layers\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up paths to audio files and genre labels\n",
        "AUDIO_PATH = 'audio'\n",
        "CSV_PATH = 'data.csv'\n"
      ],
      "metadata": {
        "id": "mZOUWl5p6hsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load audio files and extract features using librosa\n",
        "def extract_features(file_path):\n",
        "    audio_data, _ = librosa.load(file_path, sr=22050, mono=True, duration=30)\n",
        "    mfccs = librosa.feature.mfcc(y=audio_data, sr=22050, n_mfcc=20)\n",
        "    chroma_stft = librosa.feature.chroma_stft(y=audio_data, sr=22050)\n",
        "    spectral_centroid = librosa.feature.spectral_centroid(y=audio_data, sr=22050)\n",
        "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio_data, sr=22050)\n",
        "    spectral_rolloff = librosa.feature.spectral_rolloff(y=audio_data, sr=22050)\n",
        "    features = np.concatenate((np.mean(mfccs, axis=1), np.mean(chroma_stft, axis=1), np.mean(spectral_centroid), np.mean(spectral_bandwidth), np.mean(spectral_rolloff)))\n",
        "    return features"
      ],
      "metadata": {
        "id": "_Qe0y47y6hpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data from CSV file and extract features\n",
        "data = pd.read_csv(CSV_PATH)\n",
        "features = []\n",
        "labels = []\n",
        "for index, row in data.iterrows():\n",
        "    file_path = os.path.join(AUDIO_PATH, row['filename'])\n",
        "    genre = row['label']\n",
        "    features.append(extract_features(file_path))\n",
        "    labels.append(genre)"
      ],
      "metadata": {
        "id": "9hRekbvF6hmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode genre labels and scale features\n",
        "encoder = LabelEncoder()\n",
        "labels = encoder.fit_transform(labels)\n",
        "scaler = StandardScaler()\n",
        "features = scaler.fit_transform(np.array(features, dtype=float))\n"
      ],
      "metadata": {
        "id": "M4If0-yO6hjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split data into training and testing sets\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.2)"
      ],
      "metadata": {
        "id": "42mlp8tc6hgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a neural network for music genre classification\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(256, activation='relu', input_shape=(train_features.shape[1],)))\n",
        "model.add(layers.Dropout(0.3))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dropout(0.1))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model on the training set and evaluate it on the testing set\n",
        "history = model.fit(train_features, train_labels, epochs=50, batch_size=128, validation_data=(test_features, test_labels))\n"
      ],
      "metadata": {
        "id": "YZKrCtAz6hdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training and testing accuracy and loss curves\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Testing Accuracy')\n",
        "plt.title('Training and Testing Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "d6THVHHe7DXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Testing Loss')\n",
        "plt.title('Training and Testing Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jOuk51sj7GEZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}